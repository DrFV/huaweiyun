{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "\n",
    "实验平台：华为云 CPU 8核 32GiB\n",
    "\n",
    "软件环境：python3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 环境配置与数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages\r\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 60.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from lightgbm)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from lightgbm)\n",
      "Requirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from lightgbm)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ma-user/work/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_path = os.environ['HOME'] + '/work/'\n",
    "source_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file etasll2020/train_label2.csv from OBS to local /home/ma-user/work/data/train_label2.csv\n",
      "Successfully download file etasll2020/train_feature2.csv from OBS to local /home/ma-user/work/data/train_feature2.csv\n"
     ]
    }
   ],
   "source": [
    "from modelarts.session import Session\n",
    "session = Session()\n",
    "session.download_data(bucket_path=\"etasll2020/train_label2.csv\", path=source_file_path+\"data/train_label2.csv\")\n",
    "session.download_data(bucket_path=\"etasll2020/train_feature2.csv\", path=source_file_path+\"data/train_feature2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.read_csv(\"data/train_feature2.csv\")\n",
    "train_label = pd.read_csv(\"data/train_label2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18951, 14), (18951,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(train_feature)\n",
    "y_train = np.array(train_label)\n",
    "y_train = y_train.reshape(-1)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 基本调用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "def save_model(model, name):\n",
    "    joblib.dump(model, \"saved_model/\" + name)\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "def load_model(name):\n",
    "    model = joblib.load(\"saved_model/\" + name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJOBS = 8\n",
    "n_folds = 5\n",
    "\n",
    "def cross_validation(model, X, y):\n",
    "    kf = KFold(n_folds, shuffle=True)\n",
    "    mse = -cross_val_score(model, X/3600, y/3600, scoring=\"neg_mean_squared_error\", cv=kf, n_jobs=NJOBS)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 模型比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 线性模型\n",
    "* LinearRegression\n",
    "* Lasso\n",
    "* BayesianRidge\n",
    "* LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10875.51272892, 10655.46791765, 10486.90981549,  9406.74269793,\n",
       "         9655.61165091]),\n",
       " 10216.04896218152)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "score = cross_validation(model_lr, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9590.03600862, 10784.74066502, 10688.08679576,  9086.7455184 ,\n",
       "        11003.50491418]),\n",
       " 10230.62278039616)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0001, random_state=2))\n",
    "score = cross_validation(model_lasso, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8474.64181287, 11511.34416184, 10567.4388824 ,  9434.10700616,\n",
       "        11234.41755199]),\n",
       " 10244.389883050897)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_llic = LassoLarsIC()\n",
    "score = cross_validation(model_llic, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10824.91807049,  9218.73400394, 10219.57860856, 10573.92424905,\n",
       "        10281.78039415]),\n",
       " 10223.787065240456)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_br = BayesianRidge()\n",
    "score = cross_validation(model_br, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 决策树\n",
    "* DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3089.42518323, 3916.35143461, 4027.61569865, 4344.89418769,\n",
       "        4717.25911736]),\n",
       " 4019.1091243087867)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt = DecisionTreeRegressor()\n",
    "score = cross_validation(model_dt, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 K近邻\n",
    "* KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5229.86407384, 6857.72068144, 5493.36737481, 5014.92799705,\n",
       "        5923.56590775]),\n",
       " 5703.889206979349)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsRegressor(n_neighbors=3)\n",
    "score = cross_validation(model_knn, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 支持向量机\n",
    "* SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([29838.613272  , 31402.4725567 , 27963.36432543, 26199.7878413 ,\n",
       "        29961.30748378]),\n",
       " 29073.10909584241)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVR()\n",
    "score = cross_validation(model_svm, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 集成学习\n",
    "* RandomForestRegressor\n",
    "* BaggingRegressor\n",
    "* LGBMRegressor\n",
    "* XGBRegressor\n",
    "* GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2692.33021979, 3025.1277502 , 2460.15423098, 2056.23403889,\n",
       "        3106.54330023]),\n",
       " 2668.077908019478)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_jobs=NJOBS)\n",
    "score = cross_validation(model_rf, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3073.33738456, 2042.39061659, 2619.28694261, 2699.23124331,\n",
       "        3141.38738811]),\n",
       " 2715.126715036007)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bag = BaggingRegressor()\n",
    "score = cross_validation(model_bag, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4222.85007106, 3020.2175158 , 3224.17547815, 3691.79541711,\n",
       "        2881.682065  ]),\n",
       " 3408.1441094216293)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor()\n",
    "score = cross_validation(model_lgb, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5840.52617242, 5172.23873176, 4833.72376626, 4265.41251206,\n",
       "        4776.74601327]),\n",
       " 4977.7294391538)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor()\n",
    "score = cross_validation(model_xgb, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4403.13353388, 4873.31268948, 4867.09890319, 5848.82607862,\n",
       "        4367.45592384]),\n",
       " 4871.965425800985)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbdt = GradientBoostingRegressor()\n",
    "score = cross_validation(model_gbdt, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3424.34067648, 3921.46610537, 2593.36090976, 3289.04065377,\n",
       "        2623.80420741]),\n",
       " 3170.4025105578758)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "score = cross_validation(model_xgb, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4088.14041677, 3982.76516622, 3158.08436352, 3965.23156337,\n",
       "        3473.26989533]),\n",
       " 3733.4982810416977)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbdt = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state=5)\n",
    "score = cross_validation(model_gbdt, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "\n",
    "class Averaging(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2862.34707262, 2370.24371843, 2580.13991194, 1882.83686604,\n",
       "        2580.10153755]),\n",
       " 2455.1338213139848)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_averaging = Averaging((model_lgb, model_bag, model_rf, model_xgb))\n",
    "score = cross_validation(model_averaging, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacking(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred \n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2000.82823959, 2319.94728808, 2031.79929205, 3448.62416865,\n",
       "        2398.37817696]),\n",
       " 2439.9154330642255)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stacking = Stacking(base_models = (model_lgb, model_bag, model_rf, model_xgb), meta_model = model_lr)\n",
    "score = cross_validation(model_stacking, X_train, y_train)\n",
    "score, np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 训练、预测、保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = pd.read_csv(\"data/test_feature.csv\")\n",
    "test_data = pd.read_csv(\"data/A_testData0531.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_timeStamp(timeString, form=0):\n",
    "    if form == 0:\n",
    "        timeArray = time.strptime(timeString, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    if form == 1:\n",
    "        timeArray = time.strptime(timeString, '%Y/%m/%d  %H:%M:%S')\n",
    "    timeStamp = int(time.mktime(timeArray))\n",
    "    return timeStamp\n",
    "\n",
    "def timestamp_to_str(timestamp=None, format='%Y/%m/%d  %H:%M:%S'):\n",
    "    if timestamp:\n",
    "        time_tuple = time.localtime(timestamp)  # 把时间戳转换成时间元祖\n",
    "        result = time.strftime(format, time_tuple)  # 把时间元祖转换成格式化好的时间\n",
    "        return result\n",
    "    else:\n",
    "        return time.strptime(format)\n",
    "    \n",
    "def model_test(model, test_feature, test_data):\n",
    "    _test_feature = test_feature.copy()\n",
    "    _test_data = test_data.copy()\n",
    "    test_feature_array = np.array(_test_feature.iloc[:,1:])\n",
    "    _test_feature['label'] = model.predict(test_feature_array)\n",
    "    result = _test_feature[['loadingOrder','label']]\n",
    "\n",
    "    _test_data = _test_data.merge(result, on='loadingOrder', how='left')\n",
    "    _test_data['ETA'] = _test_data['onboardDate'].apply(lambda x:get_timeStamp(x,form=1)) + _test_data['label']\n",
    "    _test_data['ETA'] = _test_data['ETA'].apply(lambda x:timestamp_to_str(x))\n",
    "    _test_data.drop(['direction','TRANSPORT_TRACE'],axis=1,inplace=True)\n",
    "    #test_data['onboardDate'] = test_data['onboardDate']\n",
    "    _test_data['creatDate'] = pd.datetime.now().strftime('%Y/%m/%d  %H:%M:%S')\n",
    "    # 整理columns顺序\n",
    "    result = _test_data[['loadingOrder', 'timestamp', 'longitude', 'latitude', 'carrierName', 'vesselMMSI', 'onboardDate', 'ETA', 'creatDate']]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stacking.fit(X_train, y_train)\n",
    "result = model_test(model_stacking, test_feature, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loadingOrder</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>carrierName</th>\n",
       "      <th>vesselMMSI</th>\n",
       "      <th>onboardDate</th>\n",
       "      <th>ETA</th>\n",
       "      <th>creatDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T02:42:28.000Z</td>\n",
       "      <td>138.471062</td>\n",
       "      <td>40.278787</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/18  21:58:03</td>\n",
       "      <td>2020/06/18  23:03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T02:59:28.000Z</td>\n",
       "      <td>138.552168</td>\n",
       "      <td>40.327785</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/18  21:58:03</td>\n",
       "      <td>2020/06/18  23:03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T03:07:28.000Z</td>\n",
       "      <td>138.588250</td>\n",
       "      <td>40.352542</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/18  21:58:03</td>\n",
       "      <td>2020/06/18  23:03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T03:43:28.000Z</td>\n",
       "      <td>138.751325</td>\n",
       "      <td>40.459447</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/18  21:58:03</td>\n",
       "      <td>2020/06/18  23:03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CF946210847851</td>\n",
       "      <td>2019-04-02T04:29:28.000Z</td>\n",
       "      <td>138.969782</td>\n",
       "      <td>40.581485</td>\n",
       "      <td>OIEQNT</td>\n",
       "      <td>R5480015614</td>\n",
       "      <td>2019/04/02  02:42:28</td>\n",
       "      <td>2019/04/18  21:58:03</td>\n",
       "      <td>2020/06/18  23:03:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loadingOrder                 timestamp   longitude   latitude  \\\n",
       "0  CF946210847851  2019-04-02T02:42:28.000Z  138.471062  40.278787   \n",
       "1  CF946210847851  2019-04-02T02:59:28.000Z  138.552168  40.327785   \n",
       "2  CF946210847851  2019-04-02T03:07:28.000Z  138.588250  40.352542   \n",
       "3  CF946210847851  2019-04-02T03:43:28.000Z  138.751325  40.459447   \n",
       "4  CF946210847851  2019-04-02T04:29:28.000Z  138.969782  40.581485   \n",
       "\n",
       "  carrierName   vesselMMSI           onboardDate                   ETA  \\\n",
       "0      OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/18  21:58:03   \n",
       "1      OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/18  21:58:03   \n",
       "2      OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/18  21:58:03   \n",
       "3      OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/18  21:58:03   \n",
       "4      OIEQNT  R5480015614  2019/04/02  02:42:28  2019/04/18  21:58:03   \n",
       "\n",
       "              creatDate  \n",
       "0  2020/06/18  23:03:13  \n",
       "1  2020/06/18  23:03:13  \n",
       "2  2020/06/18  23:03:13  \n",
       "3  2020/06/18  23:03:13  \n",
       "4  2020/06/18  23:03:13  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"stacked_averaged_models5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.15.1-99273b13\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mox.file.copy_parallel('stacked_averaged_models5.csv', 's3://etasll2020/saved/stacked_averaged_models5.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
